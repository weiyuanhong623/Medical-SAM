## Medical SAMï¼šA Medical Image Semantic Segmentation Model Combining Prompt Masks and Vision Transformer

##### This is a repository for documenting undergraduate thesis projects

- Introduced the Hybrid Adapter Transformer (HAT) Block

- Conducted zero-shot and fully supervised comparative experiments on four medical image datasets and eleven benchmark models (including TransUNet, Deeplabv3+, etc.) based on seven evaluation metrics
- Medical SAM outperforms SAM and SAM-Med2D in both zero-shot and fully supervised tasks. Even without any fine-tuning, Medical SAM performs better than SAM-Med2D, which is extensively fine-tuned on over 4.6 million medical images and 19.7 million masks, on the DRIVE dataset

